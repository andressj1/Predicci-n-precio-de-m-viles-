{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Librerias--#\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV # búsqueda aleatoria de hiperparámetros \n",
    "import joblib  ### para guardar y cargar modelos\n",
    "from sklearn.preprocessing import StandardScaler ## escalar variables \n",
    "from sklearn.feature_selection import SelectKBest, f_classif,chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # Regresión logística\n",
    "from sklearn.ensemble import RandomForestClassifier  # Clasificador bosques aleatoriost \n",
    "from sklearn.tree import DecisionTreeClassifier # Arboles de decision \n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler ## escalar variable\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier #Modelo de clasificacion\n",
    "from sklearn.metrics import confusion_matrix #### Matriz de confusion \n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns #####Graficos\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import funciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----Lectura de datos----###\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/andressj1/Predicci-n-precio-de-m-viles-/refs/heads/main/Datos/df_fin\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies y Escalar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion; categoricas a dummies\n",
    "df = pd.get_dummies(df, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1958, 20)\n",
      "(1958,)\n"
     ]
    }
   ],
   "source": [
    "# Separamos variables explicativas - variable objetivo\n",
    "X1 = df.drop('price_range',axis=1)\n",
    "y = df['price_range']\n",
    "\n",
    "print(X1.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar variables \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X1)\n",
    "X2 = scaler.transform(X1)\n",
    "X = pd.DataFrame(X2,columns=X1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Selec From Model*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.1. Ridge Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14807826 -0.00397091 -0.0037951  -0.00743636  0.0082613  -0.00317897\n",
      "  -0.02776882  0.02098687 -0.1180061  -0.02613334  0.00751121 -0.0039677\n",
      "   0.00401115  0.01599757  0.00955429  0.33717986 -0.19710618 -0.18095961\n",
      "   0.0042275  -0.00213541]\n",
      " [-0.01447262  0.00444907  0.01678706  0.00346025  0.01086592  0.00909252\n",
      "   0.03465646 -0.04806438 -0.00368244  0.02971434  0.00959173  0.00253166\n",
      "  -0.01931998 -0.0359268  -0.02646579  0.15950893  0.02111461 -0.20201974\n",
      "   0.1078598   0.10489199]\n",
      " [ 0.01400606 -0.00395575 -0.00684944  0.01600108 -0.03175667 -0.02774011\n",
      "  -0.0021118   0.02327536 -0.0064283  -0.01048074 -0.03263826 -0.00814626\n",
      "  -0.00549342  0.00164768  0.02715273 -0.20932219  0.31927867 -0.08811182\n",
      "  -0.1174903  -0.0663456 ]\n",
      " [ 0.14854482  0.0034776  -0.00614252 -0.01202496  0.01262945  0.02182655\n",
      "  -0.00477584  0.00380215  0.12811685  0.00689973  0.01553533  0.0095823\n",
      "   0.02080226  0.01828154 -0.01024123 -0.2873666  -0.1432871   0.47109116\n",
      "   0.00540301 -0.03641098]]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1958 entries, 0 to 1957\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   battery_power          1958 non-null   float64\n",
      " 1   px_width               1958 non-null   float64\n",
      " 2   ram_cat_2GB            1958 non-null   float64\n",
      " 3   ram_cat_3GB            1958 non-null   float64\n",
      " 4   ram_cat_4GB            1958 non-null   float64\n",
      " 5   mobile_wt_cat_liviano  1958 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 91.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Selector de variables con Ridge\n",
    "sel_ = SelectFromModel(RidgeClassifier(alpha = 0.1, random_state = 24), max_features = 20)\n",
    "sel_.fit(X, y)\n",
    "print(sel_.estimator_.coef_)\n",
    "#Obtener variables seleccionadas\n",
    "X_new = sel_.get_support()\n",
    "\n",
    "df_ridge = X.iloc[:,X_new]\n",
    "df_ridge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.2. Gradient Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17474066 0.00111653 0.0014376  0.01537186 0.00322616 0.03021425\n",
      " 0.01002424 0.00940855 0.13469667 0.02246023 0.00261395 0.00101846\n",
      " 0.00086092 0.00335158 0.00246889 0.18001534 0.12125409 0.27971146\n",
      " 0.00225737 0.00375119]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram_cat_2GB</th>\n",
       "      <th>ram_cat_3GB</th>\n",
       "      <th>ram_cat_4GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900357</td>\n",
       "      <td>-1.146484</td>\n",
       "      <td>-0.920418</td>\n",
       "      <td>1.610174</td>\n",
       "      <td>-0.597407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.492840</td>\n",
       "      <td>1.707028</td>\n",
       "      <td>-0.920418</td>\n",
       "      <td>1.610174</td>\n",
       "      <td>-0.597407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.535536</td>\n",
       "      <td>1.077032</td>\n",
       "      <td>-0.920418</td>\n",
       "      <td>1.610174</td>\n",
       "      <td>-0.597407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.417151</td>\n",
       "      <td>1.239164</td>\n",
       "      <td>-0.920418</td>\n",
       "      <td>1.610174</td>\n",
       "      <td>-0.597407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.328463</td>\n",
       "      <td>-0.090314</td>\n",
       "      <td>1.086463</td>\n",
       "      <td>-0.621051</td>\n",
       "      <td>-0.597407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  px_width  ram_cat_2GB  ram_cat_3GB  ram_cat_4GB\n",
       "0      -0.900357 -1.146484    -0.920418     1.610174    -0.597407\n",
       "1      -0.492840  1.707028    -0.920418     1.610174    -0.597407\n",
       "2      -1.535536  1.077032    -0.920418     1.610174    -0.597407\n",
       "3      -1.417151  1.239164    -0.920418     1.610174    -0.597407\n",
       "4       1.328463 -0.090314     1.086463    -0.621051    -0.597407"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selector de variables con Gradient Boosting\n",
    "sel_ = SelectFromModel(GradientBoostingClassifier(n_estimators = 300, random_state=24))\n",
    "sel_.fit(X, y)\n",
    "print(sel_.estimator_.feature_importances_)\n",
    "#Obtener variables seleccionadas\n",
    "X_new = sel_.get_support()\n",
    "\n",
    "df_gb = X.iloc[:,X_new]\n",
    "df_gb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de selecciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge vs RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.6892352506136701\n",
      "Recall (train): 0.6954022988505747\n",
      "F1 score (train): 0.6901928737717559\n",
      "Train score (accuracy):  0.6954022988505747\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.7059224885499565\n",
      "Recall (test): 0.7091836734693877\n",
      "F1 score (test): 0.7023819871308545\n",
      "Test score (accuracy):  0.7091836734693877\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(df_ridge,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lr = LogisticRegression(max_iter=1000,class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_prob_train = lr.predict_proba(X_train)\n",
    "y_pred_prob_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.7249309317194478\n",
      "Recall (train): 0.7266922094508301\n",
      "F1 score (train): 0.7139822507691984\n",
      "Train score (accuracy):  0.7266922094508301\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.7006159569365886\n",
      "Recall (test): 0.701530612244898\n",
      "F1 score (test): 0.6871501889531658\n",
      "Test score (accuracy):  0.701530612244898\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(df_ridge,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "ranfor = RandomForestClassifier(n_estimators=300,\n",
    "                                  max_depth=30,\n",
    "                                  n_jobs=-1,\n",
    "                                  max_leaf_nodes=20,\n",
    "                                  min_samples_leaf=10,\n",
    "                                  class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = ranfor.predict(X_train)\n",
    "y_pred_test = ranfor.predict(X_test)\n",
    "y_pred_prob_train = ranfor.predict_proba(X_train)\n",
    "y_pred_prob_test = ranfor.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting vs RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.6923671737812298\n",
      "Recall (train): 0.6979565772669221\n",
      "F1 score (train): 0.6929323152097137\n",
      "Train score (accuracy):  0.6979565772669221\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.7105004269010194\n",
      "Recall (test): 0.7142857142857143\n",
      "F1 score (test): 0.7066961613938635\n",
      "Test score (accuracy):  0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(df_gb,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lr = LogisticRegression(max_iter=1000,class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_prob_train = lr.predict_proba(X_train)\n",
    "y_pred_prob_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting vs Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas vs Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas vs RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.713364183321103\n",
      "Recall (train): 0.7158365261813537\n",
      "F1 score (train): 0.7116404374077976\n",
      "Train score (accuracy):  0.7158365261813537\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.7025776055631978\n",
      "Recall (test): 0.7066326530612245\n",
      "F1 score (test): 0.6969587496518522\n",
      "Test score (accuracy):  0.7066326530612245\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lr = LogisticRegression(max_iter=1000,class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_prob_train = lr.predict_proba(X_train)\n",
    "y_pred_prob_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
