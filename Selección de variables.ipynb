{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Librerias--#\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV # búsqueda aleatoria de hiperparámetros \n",
    "import joblib  ### para guardar y cargar modelos\n",
    "from sklearn.preprocessing import StandardScaler ## escalar variables \n",
    "from sklearn.feature_selection import SelectKBest, f_classif,chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # Regresión logística\n",
    "from sklearn.ensemble import RandomForestClassifier  # Clasificador bosques aleatoriost \n",
    "from sklearn.tree import DecisionTreeClassifier # Arboles de decision \n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler ## escalar variable\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier #Modelo de clasificacion\n",
    "from sklearn.metrics import confusion_matrix #### Matriz de confusion \n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns #####Graficos\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----Lectura de datos----###\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/andressj1/Predicci-n-precio-de-m-viles-/refs/heads/main/Datos/train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies y Escalar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion; categoricas a dummies\n",
    "df = pd.get_dummies(df, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Separamos variables explicativas - variable objetivo\n",
    "X1 = df.drop('price_range',axis=1)\n",
    "y = df['price_range']\n",
    "\n",
    "print(X1.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar variables \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X1)\n",
    "X2 = scaler.transform(X1)\n",
    "X = pd.DataFrame(X2,columns=X1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Selec From Model*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.1. Ridge Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.34532801e-01  4.39342035e-03  1.84588949e-02  7.63127701e-03\n",
      "  -1.51689882e-02  1.09041706e-02 -4.30302393e-03 -1.60239213e-02\n",
      "   4.66674797e-03  1.72932783e-02  3.13545188e-03 -1.01191404e-01\n",
      "  -6.47236127e-02 -6.19800323e-01  1.02174618e-02  9.65697884e-03\n",
      "  -2.26799343e-02 -1.66633041e-02  2.26085298e-03  8.50563876e-03]\n",
      " [-1.59568698e-02  6.81266961e-04 -1.91688052e-02  1.00350708e-02\n",
      "   6.21744522e-03  8.44138373e-03  7.68520868e-03  3.55753955e-02\n",
      "   1.67389635e-03 -4.72540068e-02  2.09899412e-03  2.60745139e-02\n",
      "  -1.17888769e-02 -2.04032075e-01 -2.40711241e-04 -1.68546365e-02\n",
      "   3.52904526e-02 -6.26281348e-03  1.36577913e-02  1.82149958e-03]\n",
      " [-1.21673094e-02 -1.25135013e-02  2.63882976e-03 -1.92633119e-02\n",
      "   2.49578658e-02 -4.81210136e-02 -3.38357717e-02 -1.73340475e-02\n",
      "   4.49448528e-02  3.42979989e-02 -1.51689850e-02  6.05470535e-03\n",
      "  -2.38551460e-02  2.13191629e-01 -3.97760349e-02  7.59412179e-03\n",
      "  -6.51905143e-03  3.94609304e-02 -2.83849351e-02 -7.71983861e-03]\n",
      " [ 1.62656980e-01  7.43881399e-03 -1.92891944e-03  1.59696404e-03\n",
      "  -1.60063228e-02  2.87754593e-02  3.04535869e-02 -2.21742672e-03\n",
      "  -5.12854971e-02 -4.33727041e-03  9.93453896e-03  6.90621851e-02\n",
      "   1.00367636e-01  6.10640769e-01  2.97992844e-02 -3.96464134e-04\n",
      "  -6.09146685e-03 -1.65348129e-02  1.24662908e-02 -2.60729973e-03]]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   float64\n",
      " 1   px_height      2000 non-null   float64\n",
      " 2   px_width       2000 non-null   float64\n",
      " 3   ram            2000 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 62.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Selector de variables con Ridge\n",
    "sel_ = SelectFromModel(RidgeClassifier(alpha = 0.1, random_state = 24), max_features = 20)\n",
    "sel_.fit(X, y)\n",
    "print(sel_.estimator_.coef_)\n",
    "#Obtener variables seleccionadas\n",
    "X_new = sel_.get_support()\n",
    "\n",
    "df_ridge = X.iloc[:,X_new]\n",
    "df_ridge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1.2. Gradient Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.08877965e-01 2.11928092e-04 4.49781373e-04 1.88058167e-04\n",
      " 8.64505665e-04 1.34506520e-04 4.07786266e-03 2.27808955e-03\n",
      " 6.08715463e-03 1.38083830e-03 6.61904816e-04 4.88789195e-02\n",
      " 2.90736906e-02 7.94075443e-01 6.86893799e-04 1.16873364e-03\n",
      " 6.37234414e-04 1.59390586e-05 3.17177251e-05 2.18833456e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>ram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902597</td>\n",
       "      <td>0.391703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.495139</td>\n",
       "      <td>0.467317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.537686</td>\n",
       "      <td>0.441498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.419319</td>\n",
       "      <td>0.594569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.325906</td>\n",
       "      <td>-0.657666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power       ram\n",
       "0      -0.902597  0.391703\n",
       "1      -0.495139  0.467317\n",
       "2      -1.537686  0.441498\n",
       "3      -1.419319  0.594569\n",
       "4       1.325906 -0.657666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selector de variables con Gradient Boosting\n",
    "sel_ = SelectFromModel(GradientBoostingClassifier(n_estimators = 300, random_state=24))\n",
    "sel_.fit(X, y)\n",
    "print(sel_.estimator_.feature_importances_)\n",
    "#Obtener variables seleccionadas\n",
    "X_new = sel_.get_support()\n",
    "\n",
    "df_gb = X.iloc[:,X_new]\n",
    "df_gb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de selecciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge vs RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.9575102644406868\n",
      "Recall (train): 0.9575\n",
      "F1 score (train): 0.9574473471419328\n",
      "Train score (accuracy):  0.9575\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.9729502424658674\n",
      "Recall (test): 0.9725\n",
      "F1 score (test): 0.972514030860523\n",
      "Test score (accuracy):  0.9725\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(df_ridge,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lr = LogisticRegression(max_iter=1000,class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_prob_train = lr.predict_proba(X_train)\n",
    "y_pred_prob_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.916241865048727\n",
      "Recall (train): 0.91625\n",
      "F1 score (train): 0.9161966121372725\n",
      "Train score (accuracy):  0.91625\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.9119007528111303\n",
      "Recall (test): 0.91\n",
      "F1 score (test): 0.9104066961831343\n",
      "Test score (accuracy):  0.91\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(df_ridge,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "ranfor = RandomForestClassifier(n_estimators=300,\n",
    "                                  max_depth=30,\n",
    "                                  n_jobs=-1,\n",
    "                                  max_leaf_nodes=20,\n",
    "                                  min_samples_leaf=10,\n",
    "                                  class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = ranfor.predict(X_train)\n",
    "y_pred_test = ranfor.predict(X_test)\n",
    "y_pred_prob_train = ranfor.predict_proba(X_train)\n",
    "y_pred_prob_test = ranfor.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting vs RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.824604215404147\n",
      "Recall (train): 0.82625\n",
      "F1 score (train): 0.8252391302896952\n",
      "Train score (accuracy):  0.82625\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.8198169202347316\n",
      "Recall (test): 0.8125\n",
      "F1 score (test): 0.8143234360160251\n",
      "Test score (accuracy):  0.8125\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(df_gb,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lr = LogisticRegression(max_iter=1000,class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_prob_train = lr.predict_proba(X_train)\n",
    "y_pred_prob_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.8530622164686039\n",
      "Recall (train): 0.854375\n",
      "F1 score (train): 0.8533432944686079\n",
      "Train score (accuracy):  0.854375\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.8243541219769343\n",
      "Recall (test): 0.8175\n",
      "F1 score (test): 0.8193883197838058\n",
      "Test score (accuracy):  0.8175\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(df_gb,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "ranfor = RandomForestClassifier(n_estimators=300,\n",
    "                                  max_depth=30,\n",
    "                                  n_jobs=-1,\n",
    "                                  max_leaf_nodes=20,\n",
    "                                  min_samples_leaf=10,\n",
    "                                  class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = ranfor.predict(X_train)\n",
    "y_pred_test = ranfor.predict(X_test)\n",
    "y_pred_prob_train = ranfor.predict_proba(X_train)\n",
    "y_pred_prob_test = ranfor.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.9125118224597568\n",
      "Recall (train): 0.913125\n",
      "F1 score (train): 0.912624542821008\n",
      "Train score (accuracy):  0.913125\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.8723009350549161\n",
      "Recall (test): 0.8725\n",
      "F1 score (test): 0.8722376703785446\n",
      "Test score (accuracy):  0.8725\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "ranfor = RandomForestClassifier(n_estimators=300,\n",
    "                                  max_depth=30,\n",
    "                                  n_jobs=-1,\n",
    "                                  max_leaf_nodes=20,\n",
    "                                  min_samples_leaf=10,\n",
    "                                  class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = ranfor.predict(X_train)\n",
    "y_pred_test = ranfor.predict(X_test)\n",
    "y_pred_prob_train = ranfor.predict_proba(X_train)\n",
    "y_pred_prob_test = ranfor.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas vs RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ TRAIN ------------------------------\n",
      "Precision (train): 0.9787332529774172\n",
      "Recall (train): 0.97875\n",
      "F1 score (train): 0.9786865579837116\n",
      "Train score (accuracy):  0.97875\n",
      "------------------------------ TEST ------------------------------\n",
      "Precision (test): 0.9781689842503988\n",
      "Recall (test): 0.9775\n",
      "F1 score (test): 0.9774903455943224\n",
      "Test score (accuracy):  0.9775\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lr = LogisticRegression(max_iter=1000,class_weight=\"balanced\", random_state=42).fit(X_train,y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_prob_train = lr.predict_proba(X_train)\n",
    "y_pred_prob_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "mc_train = confusion_matrix(y_train, y_pred_train)\n",
    "mc_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Métricas para los datos de entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Métricas para los datos de prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados de entrenamiento\n",
    "print('-'*30, 'TRAIN', '-'*30)\n",
    "print(f'Precision (train): {precision_train}')\n",
    "print(f'Recall (train): {recall_train}')\n",
    "print(f'F1 score (train): {f1_train}')\n",
    "print('Train score (accuracy): ', accuracy_train)\n",
    "\n",
    "# Imprimir los resultados de prueba\n",
    "print('-'*30, 'TEST', '-'*30)\n",
    "print(f'Precision (test): {precision_test}')\n",
    "print(f'Recall (test): {recall_test}')\n",
    "print(f'F1 score (test): {f1_test}')\n",
    "print('Test score (accuracy): ', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usara el \"Todas vs RL\" debido a que muestra un mayor F1 y una mayor precision, ademas no muestra sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['price_range'] = df['price_range']\n",
    "X.to_csv(\"Datos\\\\X\", index=False, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
